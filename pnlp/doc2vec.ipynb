{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TFIDF\n",
    "\n",
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"]\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF for all words in the vocabulary [1.51082562 1.22314355 1.51082562 1.91629073 1.22314355 1.91629073]\n",
      "----------\n",
      "All words in the vocabulary ['bites', 'dog', 'eats', 'food', 'man', 'meat']\n",
      "----------\n",
      "TFIDF representation for all documents in our corpus\n",
      " [[0.65782931 0.53256952 0.         0.         0.53256952 0.        ]\n",
      " [0.65782931 0.53256952 0.         0.         0.53256952 0.        ]\n",
      " [0.         0.44809973 0.55349232 0.         0.         0.70203482]\n",
      " [0.         0.         0.55349232 0.70203482 0.44809973 0.        ]]\n",
      "----------\n",
      "Tfidf representation for 'dog and man are friends':\n",
      " [[0.         0.70710678 0.         0.         0.70710678 0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shiv1\\miniconda3\\envs\\gendev\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "bow_rep_tfidf = tfidf.fit_transform(processed_docs)\n",
    "\n",
    "#IDF for all words in the vocabulary\n",
    "print(\"IDF for all words in the vocabulary\",tfidf.idf_)\n",
    "print(\"-\"*10)\n",
    "#All words in the vocabulary.\n",
    "print(\"All words in the vocabulary\",tfidf.get_feature_names())\n",
    "print(\"-\"*10)\n",
    "\n",
    "#TFIDF representation for all documents in our corpus \n",
    "print(\"TFIDF representation for all documents in our corpus\\n\",bow_rep_tfidf.toarray()) \n",
    "print(\"-\"*10)\n",
    "\n",
    "temp = tfidf.transform([\"dog and man are friends\"])\n",
    "print(\"Tfidf representation for 'dog and man are friends':\\n\", temp.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using gensim, spacy, nltk to train a doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages needed for this experiment\n",
    "#!pip install gensim==3.6.0\n",
    "#!pip install spacy==2.2.4\n",
    "#!pip install nltk==3.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shiv1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"dog bites man\",\n",
    "        \"man bites dog\",\n",
    "        \"dog eats meat\",\n",
    "        \"man eats food\",\n",
    "        \"man is not sheep\",\n",
    "        \"king is made\",\n",
    "        \"queen is chosen\"]\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(word.lower()), tags=[str(i)]) for i, word in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['dog', 'bites', 'man'], tags=['0']),\n",
       " TaggedDocument(words=['man', 'bites', 'dog'], tags=['1']),\n",
       " TaggedDocument(words=['dog', 'eats', 'meat'], tags=['2']),\n",
       " TaggedDocument(words=['man', 'eats', 'food'], tags=['3']),\n",
       " TaggedDocument(words=['man', 'is', 'not', 'sheep'], tags=['4']),\n",
       " TaggedDocument(words=['king', 'is', 'made'], tags=['5']),\n",
       " TaggedDocument(words=['queen', 'is', 'chosen'], tags=['6'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbow\n",
    "model_dbow = Doc2Vec(tagged_data,vector_size=20, min_count=1, epochs=2,dm=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01955524 -0.01711161 -0.01388226 -0.00497426  0.00237928 -0.00134615\n",
      " -0.02040341 -0.02425806  0.01450477 -0.018003    0.00464677 -0.00692584\n",
      "  0.01673512  0.01154605 -0.02399587 -0.01162305  0.01260396  0.01774428\n",
      "  0.01493157  0.02138604]\n"
     ]
    }
   ],
   "source": [
    "# Feature vector of man eats food\n",
    "print(model_dbow.infer_vector(['man','eats','food']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.4304395914077759),\n",
       " ('chosen', 0.2972422242164612),\n",
       " ('dog', 0.25138211250305176),\n",
       " ('food', 0.20270395278930664),\n",
       " ('not', 0.1977836638689041)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 most simlar words\n",
    "model_dbow.wv.most_similar(\"man\",topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2513821"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check similarity score between dog and man\n",
    "model_dbow.wv.n_similarity([\"dog\"],[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Vector of man eats food\n",
      "  [ 0.01956423 -0.01711311 -0.01390795 -0.00498287  0.00240287 -0.00136158\n",
      " -0.02038174 -0.02426959  0.01448358 -0.01801188  0.0046541  -0.00692043\n",
      "  0.01671058  0.01152617 -0.02401017 -0.01160503  0.01260363  0.01773504\n",
      "  0.01495108  0.02139715]\n",
      "Most similar words to cat in food corpus\n",
      " [('king', 0.3562750220298767), ('man', 0.20270395278930664), ('made', 0.16116014122962952), ('not', 0.13961383700370789), ('queen', 0.1377629041671753)]\n",
      "Similarity between man and queen:  -0.066151686\n"
     ]
    }
   ],
   "source": [
    "#dm\n",
    "model_dm = Doc2Vec(tagged_data, min_count=1, vector_size=20, epochs=2,dm=1)\n",
    "\n",
    "print(\"Inference Vector of man eats food\\n \",model_dm.infer_vector(['man','eats','food']))\n",
    "\n",
    "print(\"Most similar words to cat in food corpus\\n\",model_dm.wv.most_similar(\"food\",topn=5))\n",
    "print(\"Similarity between man and queen: \",model_dm.wv.n_similarity([\"queen\"],[\"man\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error when we compare words not in vocabulary\n",
    "# model_dm.wv.n_similarity(['covid'],['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gendev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
